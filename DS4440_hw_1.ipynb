{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of DS4440-hw-1",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jamesgeziqian/DS-4440-Homework-F20/blob/master/DS4440_hw_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMNRa-F1-Qfw"
      },
      "source": [
        "### DS4440: Homework 1\n",
        "\n",
        "This homework covers gradient descent, and logistic regression for (binary) classification, and PyTorch.\n",
        "\n",
        "You are allowed to upload a *single* notebook file (modifying this starter notebook) to Piazza that contains answers to all problems, including the written ones (for which you much use [LaTeX](https://www.overleaf.com/learn/latex/Free_online_introduction_to_LaTeX_(part_1))).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8l5L3Ucx-oq3"
      },
      "source": [
        "Your name: Ziqian Ge"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91u_8Npq--w_"
      },
      "source": [
        "## Q1: Deriving the Gradient (*35 points*)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhwpaeeQ_bdB"
      },
      "source": [
        "Assume we want to perform binary classification, i.e., $y_i \\in \\{0,1\\}$.\n",
        "In logistic regression, we posit the following model (parameterized by ${\\bf w}$): \n",
        "\n",
        "> $p(y_i=1|{\\bf x}_i, {\\bf w}) = \\sigma({\\bf w} \\cdot {\\bf x}_i)$\n",
        "\n",
        "Where $\\sigma$ is the sigmoid function: $\\sigma(z) = \\frac{1}{1 + e^{-z}}$. \n",
        "\n",
        "\n",
        "\n",
        "The log-likelihood for this model is:\n",
        "\n",
        "> $LL({\\bf w}| {\\bf x}, {\\bf y}) = \\sum_i y_i {\\text {ln}}\\{p(y_i|{\\bf x}_i, {\\bf w})\\} + (1 - y_i) {\\text{ln}}\\{1 - p(y_i|{\\bf x}_i, {\\bf w})\\}$\n",
        "\n",
        "\n",
        "\n",
        "Formulate this as a **minimization** problem for gradient descent, and derive the gradient with respect to the parameters ${\\bf w}$. **Show your steps**.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NaNTifCZlLZL"
      },
      "source": [
        "### Q1 Answer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouy7dAVQBvYi"
      },
      "source": [
        "$LL(w|x, y) = \\sum_i y_i \\ln\\{\\frac{1}{1 + e^{-w\\cdot x_i}}\\} + (1- y_i)\\ln\\{1 - \\frac{1}{1 + e^{-w\\cdot x_i}}\\}$\n",
        "\n",
        "$ = \\sum_i y_i \\ln\\{\\frac{1}{1 + e^{-w\\cdot x_i}}\\} + (1 - y_i)\\ln\\{\\frac{e^{-w\\cdot x_i}}{1 + e^{-w\\cdot x_i}}\\}$\n",
        "\n",
        "$ = \\sum_i y_i \\ln\\{\\frac{1}{1 + e^{-w\\cdot x_i}}\\} + (1 - y_i)\\ln\\{\\frac{e^{-w\\cdot x_i}\\cdot e^{w\\cdot x_i}}{e^{w\\cdot x_i} + e^{-w\\cdot x_i} \\cdot e^{w\\cdot x_i}}\\}$\n",
        "\n",
        "$ = \\sum_i y_i \\ln\\{\\frac{1}{1 + e^{-w\\cdot x_i}}\\} + (1 - y_i)\\ln\\{\\frac{1}{e^{w\\cdot x_i} + 1}\\}$\n",
        "\n",
        "$ = \\sum_i y_i \\ln\\{\\frac{1}{1 + e^{-w\\cdot x_i}}\\} + \\ln\\{\\frac{1}{e^{w\\cdot x_i} + 1}\\} - y_i \\ln\\{\\frac{1}{e^{w\\cdot x_i} + 1}\\}$\n",
        "\n",
        "$ = \\sum_i y_i (\\ln\\{\\frac{1}{1 + e^{-w\\cdot x_i}}\\} - \\ln\\{\\frac{1}{1 + e^{w\\cdot x_i}}\\}) + \\ln\\{\\frac{1}{1 + e^{w\\cdot x_i}}\\}$\n",
        "\n",
        "$ = \\sum_i y_i \\ln\\{\\frac{1 + e^{w\\cdot x_i}}{1 + e^{-w\\cdot x_i}}\\} + \\ln\\{1\\} - \\ln\\{{1 + e^{w\\cdot x_i}}\\}$\n",
        "\n",
        "$ = \\sum_i y_i \\ln\\{\\frac{(1 + e^{w\\cdot x_i})\\cdot e^{w\\cdot x_i}}{(1 + e^{-w\\cdot x_i})\\cdot e^{w\\cdot x_i}}\\} - \\ln\\{{1 + e^{w\\cdot x_i}}\\}$\n",
        "\n",
        "$ = \\sum_i y_i \\ln\\{\\frac{(1 + e^{w\\cdot x_i})\\cdot e^{w\\cdot x_i}}{e^{w\\cdot x_i} + e^{-w\\cdot x_i}\\cdot e^{w\\cdot x_i}}\\} - \\ln\\{{1 + e^{w\\cdot x_i}}\\}$\n",
        "\n",
        "$ = \\sum_i y_i \\ln\\{\\frac{(1 + e^{w\\cdot x_i})\\cdot e^{w\\cdot x_i}}{e^{w\\cdot x_i} + 1}\\} - \\ln\\{{1 + e^{w\\cdot x_i}}\\}$\n",
        "\n",
        "$ = \\sum_i y_i \\ln\\{e^{w\\cdot x_i}\\} - \\ln\\{{1 + e^{w\\cdot x_i}}\\}$\n",
        "\n",
        "$ = \\sum_i y_i \\cdot w\\cdot x_i - \\ln\\{{1 + e^{w\\cdot x_i}}\\}$\n",
        "\n",
        "$\\frac{\\partial}{\\partial w} LL(w|x, y) = \\frac{\\partial}{\\partial w} \\sum_i y_i \\cdot w\\cdot x_i - \\ln\\{1 + e^{w\\cdot x_i}\\}$\n",
        "\n",
        "$ = \\sum_i y_i \\cdot x_i - \\frac{x_i \\cdot e^{w \\cdot x_i}}{1 + e^{w\\cdot x_i}}$\n",
        "\n",
        "$ = \\sum_i (y_i - \\frac{e^{w \\cdot x_i}}{1 + e^{w\\cdot x_i}})\\cdot x_i$\n",
        "\n",
        "$ = \\sum_i (y_i - \\frac{e^{w \\cdot x_i} \\cdot e^{-w \\cdot x_i}}{(1 + e^{w\\cdot x_i})\\cdot e^{-w \\cdot x_i}})\\cdot x_i$\n",
        "\n",
        "$ = \\sum_i (y_i - \\frac{1}{e^{-w\\cdot x_i} + 1})\\cdot x_i$\n",
        "\n",
        "$ = \\sum_i (y_i - \\sigma(w\\cdot x_i))\\cdot x_i$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qS3kSK6jtTXZ"
      },
      "source": [
        "# Logistic Regression: 3-ways!\n",
        "\n",
        "In this section you will implement logistic regression in two different ways.\n",
        "For each, fit to the simple Iris data; you can get the `X`, `y` values via the provided helper function.\n",
        "Do not include bias (`intercept') terms. \n",
        "\n",
        "For each version of LR below, divvy your data into a validation set (we'll say 10% of the iris X, y), and a training set (the rest)\n",
        "Compute a validation loss each epoch, and retain these\n",
        "Make plots of your validation losses (a helper function is provided).\n",
        "Print your model weights.\n",
        "Don't forget to rerun everything when you have finished!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgsQfNovC1_g"
      },
      "source": [
        "#### Shared imports and helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ah0eVS_H_CwZ"
      },
      "source": [
        "# imports\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd \n",
        "import sklearn\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import accuracy_score, log_loss\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def get_iris_X_y(shuffle_instances=True):\n",
        "  '''\n",
        "  The Iris dataset is a famous dataset comprising flower characteristics.\n",
        "  We'll recast as a binary classification task.\n",
        "  '''\n",
        "  iris_df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data', \n",
        "                   header=None)\n",
        "  y = iris_df.iloc[0:100, 4].values \n",
        "  y = np.where(y == 'Iris-setosa', -1, 1)\n",
        "  y[y<0] = 0 # convert to 1/0 labels\n",
        "  X = iris_df.iloc[0:100, [0, 2]].values\n",
        "  if shuffle_instances:\n",
        "    X, y = shuffle(X, y, random_state=0)\n",
        "  return X, y\n",
        "\n",
        "\n",
        "def sigmoid(x):\n",
        "  ''' a useful helper function. '''\n",
        "  return 1/(1+np.exp(-x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1VdyidqCMRE"
      },
      "source": [
        "### Q2. Pure `numpy` implementation (*35 points*)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsBcCreHsFuS"
      },
      "source": [
        "def gd_func_gradient(x, y, w):\n",
        "  \"\"\"\n",
        "  Parameters\n",
        "  x: (n x d) matrix comprising n instances with d dimensions/features\n",
        "  y: (n x 1) vector comprising labels (0/1)\n",
        "  w: (d x 1) weight factor\n",
        "\n",
        "  Return\n",
        "  ---\n",
        "  np.ndarray (d x 1)\n",
        "  \"\"\"\n",
        "  return np.matmul(x.T, y - sigmoid(np.matmul(x, w)))\n",
        "\n",
        "\n",
        "def validate_result(theta, x, y):\n",
        "  expected_y = sigmoid(np.matmul(x, theta))\n",
        "  return log_loss(y_true=y, y_pred=expected_y)\n",
        "\n",
        "\n",
        "def data_split(X, y, *args, **kwargs):\n",
        "  X_train, X_val, y_train, y_val = train_test_split(X, y, *args, **kwargs)\n",
        "  y_train, y_val = (np.vstack(y_train), np.vstack(y_val))\n",
        "  return X_train, X_val, y_train, y_val\n",
        "\n",
        "\n",
        "def LR_SGD(X, y, epochs, alpha=0.01):\n",
        "  '''\n",
        "  Parameters\n",
        "  ---\n",
        "  X: (n x d) matrix comprising n instances with d dimensions/features.\n",
        "  y: (n x 1) vector comprising labels (0/1)\n",
        "  epochs: number of epochs to run\n",
        "  alpha: the learning rate\n",
        "  '''\n",
        "  X_train, X_val, y_train, y_val = data_split(X, y, test_size=0.1, random_state=0)\n",
        "\n",
        "  curr_w = np.vstack(np.zeros(X_train[0].shape))\n",
        "  episilon = 0.00001\n",
        "  losses = []\n",
        "  for i in range(0, epochs):\n",
        "    new_dir = gd_func_gradient(X_train, np.vstack(y_train), curr_w)\n",
        "    new_w = curr_w + new_dir * alpha\n",
        "    loss = validate_result(new_w, X_val, y_val)\n",
        "    # print('Loss of epoch {}: {}'.format(i, loss))\n",
        "    losses.append(loss)\n",
        "    if loss < episilon or np.any(np.isnan(new_w)):\n",
        "      msg = (\"Gradient descent reaches np.nan!\"\n",
        "      \" Consider the function does not converge with current α = {}.\\n\".format(alpha)\n",
        "      if np.any(np.isnan(new_w)) else \"\")\n",
        "      print(\"{}Stop at iteration: {}; with α = {}\".format(msg, i + 1, alpha))\n",
        "      curr_w = new_w\n",
        "      break\n",
        "    curr_w = new_w\n",
        "\n",
        "  return curr_w, losses"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxJHh6MVLkAf",
        "outputId": "ea674635-63e4-477e-f92b-dbf6ad57f875",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "data = get_iris_X_y()\n",
        "w_np, loss_np = LR_SGD(data[0], data[1], 10000)\n",
        "x_plot = np.linspace(0, len(loss_np), num=len(loss_np), endpoint=False)\n",
        "plt.scatter(x_plot, loss_np)\n",
        "print(w_np)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-4.80648042]\n",
            " [ 9.66758218]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWsAAAD4CAYAAAAqw8chAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAPpklEQVR4nO3db2xk1X3G8eep18CUUAzFQrsLqkGKXKGmyVILgYhQSxrMnyhZRXkBahuSplqp/0TaytFaqVTxKrSuohA1SrIipFEhkIQ4brRJcGlCVEUqm3pjghcWl4UQ2FnoDq0ckmgExvn1xRzvjo3tGYc7nnvG34808p1zr69/Z4732Tvn3vF1RAgAUG6/0u0CAACtEdYAkAHCGgAyQFgDQAYIawDIwI5O7PSCCy6IoaGhTuwaAHrS4cOHX4qIwfXWdySsh4aGNDMz04ldA0BPsv3jjdYzDQIAGSCsASADhDUAZICwBoAMENYAkIGOXA3yy5iarWpiel4nFuraNVDR2Oiw9u7Z3e2yAKAU2jqytj1g+wHbT9o+avuqIouYmq1qfHJO1YW6QlJ1oa7xyTlNzVaL/DEAkK12p0HulPRgRPympLdKOlpkERPT86ovLq1oqy8uaWJ6vsgfAwDZajkNYvtcSddI+oAkRcSrkl4tsogTC/VNtQPAdtPOkfUlkmqSPm971vZdts9evZHtfbZnbM/UarVNFbFroLKpdgDYbtoJ6x2SLpf06YjYI+nnkvav3igiDkTESESMDA6u+/H2NY2NDqvS37eirdLfp7HR4U3tBwB6VTthfVzS8Yg4lJ4/oEZ4F2bvnt362Hvfot0DFVnS7oGKPvbet3A1CAAkLeesI+JF28/bHo6IeUnvkPRE0YXs3bObcAaAdbR7nfVfSrrX9hmSnpH0wc6VBABYra2wjohHJY10uBYAwDr4uDkAZICwBoAMENYAkAHCGgAyQFgDQAYIawDIAGENABkgrAEgA4Q1AGSAsAaADBDWAJABwhoAMkBYA0AGCGsAyABhDQAZIKwBIAOENQBkgLAGgAwQ1gCQAcIaADJAWANABghrAMgAYQ0AGSCsASADO9rZyPazkn4qaUnSaxEx0smiAAArtRXWye9FxEsdqwQAsC6mQQAgA+2GdUj6N9uHbe9bawPb+2zP2J6p1WrFVQgAaDus3x4Rl0u6QdKf275m9QYRcSAiRiJiZHBwsNAiAWC7ayusI6Kavp6U9DVJV3SyKADASi3D2vbZts9ZXpZ0naQjnS4MAHBaO1eDXCjpa7aXt/9iRDzY0aoAACu0DOuIeEbSW7egFgDAOrh0DwAyQFgDQAYIawDIAGENABkgrAEgA4Q1AGSAsAaADBDWAJABwhoAMkBYA0AGCGsAyABhDQAZIKwBIAOENQBkgLAGgAwQ1gCQAcIaADJAWANABghrAMgAYQ0AGSCsASADhDUAZICwBoAMtB3Wtvtsz9o+2MmCAACvt5kj69skHe1UIQCA9bUV1rYvknSTpLs6Ww4AYC3tHll/QtJHJP2ig7UAANbRMqxtv0vSyYg43GK7fbZnbM/UarXCCgQAtHdkfbWkd9t+VtL9kq61fc/qjSLiQESMRMTI4OBgwWUCwPbWMqwjYjwiLoqIIUk3S/pORPxhxysDAJzCddYAkIEdm9k4Ir4r6bsdqQQAsC6OrAEgA4Q1AGSAsAaADBDWAJABwhoAMkBYA0AGCGsAyMCmrrPupKnZqiam53Vioa5dAxWNjQ5r757d3S4LAEqhFGE9NVvV+OSc6otLkqTqQl3jk3OSRGADgEoyDTIxPX8qqJfVF5c0MT3fpYoAoFxKEdYnFuqbageA7aYUYb1roLKpdgDYbkoR1mOjw6r0961oq/T3aWx0uEsVAUC5lOIE4/JJRK4GAYC1lSKspUZgE84AsLZSTIMAADZGWANABghrAMgAYQ0AGSCsASADhDUAZICwBoAMENYAkAHCGgAy0DKsbZ9l+/u2f2j7cdu3b0VhAIDT2vm4+SuSro2In9nul/Q929+KiEc6XBsAIGkZ1hERkn6WnvanR3SyKADASm3NWdvus/2opJOSHoqIQ2tss8/2jO2ZWq1WdJ0AsK21FdYRsRQRb5N0kaQrbP/WGtsciIiRiBgZHBwsuk4A2NY2dTVIRCxIeljS9Z0pBwCwlnauBhm0PZCWK5LeKenJThcGADitnatBdkr6gu0+NcL9yxFxsLNlAQCatXM1yGOS9mxBLQCAdZTmtl5Ts1XuwQgA6yhFWE/NVjU+Oaf64pIkqbpQ1/jknCQR2ACgkvxtkInp+VNBvay+uKSJ6fkuVQQA5VKKsD6xUN9UOwBsN6UI610DlU21A8B2U4qwHhsdVqW/b0Vbpb9PY6PDXaoIAMqlFCcYl08icjUIAKytFGEtNQKbcAaAtZViGgQAsDHCGgAyQFgDQAYIawDIAGENABkgrAEgA4Q1AGSAsAaADBDWAJABwhoAMkBYA0AGCGsAyABhDQAZIKwBIAOENQBkgLAGgAy0DGvbF9t+2PYTth+3fdtWFAYAOK2dO8W8JulvIuIHts+RdNj2QxHxRIdrAwAkLY+sI+KFiPhBWv6ppKOSuP8WAGyhTc1Z2x6StEfSoTXW7bM9Y3umVqsVUx0AQNImwtr2myR9VdKHI+Ll1esj4kBEjETEyODgYJE1AsC211ZY2+5XI6jvjYjJzpYEAFit5QlG25b0OUlHI+LjnSpkaraqiel5nVioa9dARWOjw9q7h6lxAJDaO7K+WtIfSbrW9qPpcWORRUzNVjU+OafqQl0hqbpQ1/jknKZmq0X+GADIVssj64j4niR3soiJ6XnVF5dWtNUXlzQxPc/RNQCoJJ9gPLFQ31Q7AGw3pQjrXQOVTbUDwHZTirAeGx1Wpb9vRVulv09jo8NdqggAyqWdj5t33PK8NFeDAMDaShHWUiOwCWcAWFsppkEAABsjrAEgA4Q1AGSAsAaADBDWAJABwhoAMkBYA0AGCGsAyABhDQAZIKwBIAOENQBkgLAGgAwQ1gCQAcIaADJAWANABghrAMgAYQ0AGSCsASADhDUAZKBlWNu+2/ZJ20e2oiAAwOu1c2T9z5Ku73AdAIANtAzriPgPSf+3BbUAANZR2Jy17X22Z2zP1Gq1onYLAFCBYR0RByJiJCJGBgcHi9otAEBcDQIAWSCsASAD7Vy6d5+k/5Q0bPu47Q91viwAQLMdrTaIiFu2ohAAwPqYBgGADBDWAJCBltMgW2VqtqqJ6XmdWKhr10BFY6PD2rtnd7fLAoBSKEVYT81WNT45p/rikiSpulDX+OScJBHYAKCSTINMTM+fCupl9cUlTUzPd6kiACiXUoT1iYX6ptoBYLspRVjvGqhsqh0AtptShPXY6LAq/X0r2ir9fRobHe5SRQBQLqU4wbh8EpGrQQBgbaUIa6kR2IQzAKytFNMgAICNEdYAkAHCGgAyQFgDQAYIawDIAGENABkgrAEgA4Q1AGSAsAaADBDWAJABwhoAMkBYA0AGSvOHnH777x7Uy6+cvlvMr53Zp8duv76LFQFAeZTiyHp1UEvSy68saWj/N/S3U3NdqgoAyqOtI2vb10u6U1KfpLsi4o4ii1gd1M3ueeQ53fPIc0X+OADouGfvuKnQ/bU8srbdJ+lTkm6QdJmkW2xfVmgVANBjhvZ/o9D9tTMNcoWkYxHxTES8Kul+Se8ptAoAwIbaCevdkp5ven48ta1ge5/tGdsztVqtqPoAACrwBGNEHIiIkYgYGRwcLGq3AAC1F9ZVSRc3Pb8otRWm6Il4AOg17YT1f0l6s+1LbJ8h6WZJXy+6kGfvuInQBtAzis6zlpfuRcRrtv9C0rQal+7dHRGPF1pFEwIbAF6vreusI+Kbkr7Z4VoAAOsoxScYAQAbI6wBIAOENQBkgLAGgAw4IorfqV2T9ONf8tsvkPRSgeXkgD73vu3WX4k+b9ZvRMS6nyjsSFi/EbZnImKk23VsJfrc+7ZbfyX6XDSmQQAgA4Q1AGSgjGF9oNsFdAF97n3brb8SfS5U6easAQCvV8YjawDAKoQ1AGSgNGFt+3rb87aP2d7f7XreCNsX237Y9hO2H7d9W2o/3/ZDtp9KX89L7bb9ydT3x2xf3rSvW9P2T9m+tVt9aoftPtuztg+m55fYPpT69aX0J3Zl+8z0/FhaP9S0j/HUPm97tDs9aZ/tAdsP2H7S9lHbV/XyONv+q/Q7fcT2fbbP6sVxtn237ZO2jzS1FTautn/H9lz6nk/adsuiIqLrDzX+9OrTki6VdIakH0q6rNt1vYH+7JR0eVo+R9J/q3Gz4X+QtD+175f092n5RknfkmRJV0o6lNrPl/RM+npeWj6v2/3boN9/LemLkg6m51+WdHNa/oykP03LfybpM2n5ZklfSsuXpbE/U9Il6Xeir9v9atHnL0j6k7R8hqSBXh1nNW7n9yNJlabx/UAvjrOkayRdLulIU1th4yrp+2lbp++9oWVN3X5RUuFXSZpuej4uabzbdRXYv3+V9E5J85J2pradkubT8mcl3dK0/Xxaf4ukzza1r9iuTA817iD0bUnXSjqYfglfkrRj9Rir8bfRr0rLO9J2Xj3uzduV8SHp3BReXtXek+Os0/djPT+N20FJo706zpKGVoV1IeOa1j3Z1L5iu/UeZZkGaeumvDlKb/32SDok6cKIeCGtelHShWl5vf7n9Lp8QtJHJP0iPf91SQsR8Vp63lz7qX6l9T9J2+fUX6lxVFiT9Pk0/XOX7bPVo+McEVVJ/yjpOUkvqDFuh9X747ysqHHdnZZXt2+oLGHdk2y/SdJXJX04Il5uXheN/1J74rpJ2++SdDIiDne7li22Q423yp+OiD2Sfq7G2+NTemycz5P0HjX+k9ol6WxJ13e1qC7pxriWJaw7flPerWa7X42gvjciJlPz/9jemdbvlHQyta/X/1xel6slvdv2s5LuV2Mq5E5JA7aX70bUXPupfqX150r6X+XT32XHJR2PiEPp+QNqhHevjvPvS/pRRNQiYlHSpBpj3+vjvKyoca2m5dXtGypLWG/JTXm3Sjqz+zlJRyPi402rvi5p+YzwrWrMZS+3vz+dVb5S0k/S261pSdfZPi8d1VyX2kolIsYj4qKIGFJj7L4TEX8g6WFJ70ubre7v8uvwvrR9pPab01UEl0h6sxonYkopIl6U9Lzt4dT0DklPqEfHWY3pjytt/2r6HV/ub0+Pc5NCxjWte9n2lel1fH/TvtbX7Un8pkn2G9W4auJpSR/tdj1vsC9vV+Mt0mOSHk2PG9WYr/u2pKck/buk89P2lvSp1Pc5SSNN+/pjScfS44Pd7lsbff9dnb4a5FI1/hEek/QVSWem9rPS82Np/aVN3//R9DrMq40z5N1+SHqbpJk01lNqnPXv2XGWdLukJyUdkfQvalzR0XPjLOk+NeblF9V4B/WhIsdV0kh6DZ+W9E9adZJ6rQcfNweADJRlGgQAsAHCGgAyQFgDQAYIawDIAGENABkgrAEgA4Q1AGTg/wG7ycvnjGeTFwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynhblmNwsPi3"
      },
      "source": [
        "### Q3 `pytorch` implementation -- **no NN module** (*20 points*)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0L8JGXBtsjln",
        "outputId": "635dce64-8c84-4bbf-a57e-144273e5472b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "!pip3 install torch\n",
        "\n",
        "import torch\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.6.0+cu101)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYQpSQrNsnuH"
      },
      "source": [
        "def loss_ll(y_pred, y_true):\n",
        "  return -torch.sum(y_true * torch.log(y_pred) + (1 - y_true) * torch.log(1 - y_pred))\n",
        "\n",
        "\n",
        "def LR_torch_no_nn(X, y):\n",
        "  X_train, X_val, y_train, y_val = data_split(X, y, test_size=0.1, random_state=0)\n",
        "  X_train_t = Variable(torch.from_numpy(X_train).float(), requires_grad=True)\n",
        "  y_train_t = Variable(torch.from_numpy(y_train).float())\n",
        "  X_val_t = torch.from_numpy(X_val).float()\n",
        "  y_val_t = torch.from_numpy(y_val).float()\n",
        "\n",
        "  epochs = 100000\n",
        "  alpha = 0.0005\n",
        "  w = Variable(torch.ones(len(X_train[0]), 1), requires_grad=True)\n",
        "  val_losses = np.array([])\n",
        "  loss_func = loss_ll\n",
        "\n",
        "  for i in range(epochs):\n",
        "    preds = torch.sigmoid(X_train_t @ w)\n",
        "    loss = loss_ll(preds, y_train_t)\n",
        "    loss.backward()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      w -= w.grad * alpha\n",
        "      w.grad.zero_()\n",
        "    \n",
        "    val_loss_np = loss_func(torch.sigmoid(X_val_t @ w), y_val_t).detach().numpy()\n",
        "    val_losses = np.append(val_losses, [val_loss_np])\n",
        "    \n",
        "  return w, val_losses"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqaXk6ZVtldk",
        "outputId": "7f703ce8-4592-47e4-a0fc-cd90de9567eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        }
      },
      "source": [
        "w_torch_no_nn, l_torch_no_nn = LR_torch_no_nn(data[0], data[1])\n",
        "print(w_torch_no_nn)\n",
        "x_plot = np.linspace(0, len(l_torch_no_nn), num=len(l_torch_no_nn), endpoint=False)\n",
        "plt.scatter(x_plot, l_torch_no_nn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-4.3243],\n",
            "        [ 8.6795]], requires_grad=True)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f14902b1390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 185
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mK1ERujYstSm"
      },
      "source": [
        "### Q4 `pytorch` implementation -- **with the NN module** (*10 points*)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drynANlos8gb"
      },
      "source": [
        "import torch.nn as nn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uu08ngNscRe"
      },
      "source": [
        "class IrisLogistic(nn.Module):\n",
        "\n",
        "  def __init__(self, d):\n",
        "    super(IrisLogistic, self).__init__()\n",
        "    self.linear = nn.Linear(d, 1, bias=False)\n",
        "\n",
        "  def forward(self, X):\n",
        "    return self.linear(X)\n",
        "\n",
        "\n",
        "def LR_torch(X, y):\n",
        "  X_train, X_val, y_train, y_val = data_split(X, y, test_size=0.1, random_state=0)\n",
        "  X_train_t = torch.from_numpy(X_train).float()\n",
        "  y_train_t = torch.from_numpy(y_train).float()\n",
        "  X_val_t = torch.from_numpy(X_val).float()\n",
        "  y_val_t = torch.from_numpy(y_val).float()\n",
        "\n",
        "\n",
        "  epochs = 100000\n",
        "  alpha = 0.1\n",
        "  n, _ = X_train.shape\n",
        "  bs = 10\n",
        "\n",
        "  model = IrisLogistic(d=len(X_train[0]))\n",
        "  loss_func = nn.BCEWithLogitsLoss()\n",
        "  val_losses = np.array([])\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    pred = model(X_train_t)\n",
        "    loss = loss_func(pred, y_train_t)\n",
        "    loss.backward()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for w in model.parameters():\n",
        "        w -= w.grad * alpha\n",
        "        w.grad.zero_()\n",
        "\n",
        "    val_loss_np = loss_func(model(X_val_t), y_val_t).detach().numpy()\n",
        "    val_losses = np.append(val_losses, [val_loss_np])\n",
        "\n",
        "  return model, val_losses"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gp5ags7h8N_N",
        "outputId": "69491ef6-c5cf-4f7e-a711-8716bb556368",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "m, l = LR_torch(data[0], data[1])\n",
        "x_plot = np.linspace(0, len(l), num=len(l), endpoint=False)\n",
        "plt.scatter(x_plot, l)\n",
        "print(list(m.parameters()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parameter containing:\n",
            "tensor([[-4.8790,  9.8162]], requires_grad=True)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}